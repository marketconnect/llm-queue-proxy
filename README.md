# llm-queue-proxy

**llm-queue-proxy** is a smart, self-hosted proxy for LLM APIs (like OpenAI) that automatically queues and spaces requests to avoid rate limits.

Ideal for multi-agent systems, microservices, or corporate environments where multiple apps share the same API key.

---

## âœ¨ Features

- â³ Smart queueing (no 429 errors)
- ğŸ§  Rate limiting per minute
- ğŸ” Automatic retry with delay
- ğŸ§µ Minimal threading (no Redis, no DB)
- ğŸªª Works with `systemd` as a Linux service
- ğŸ” Secrets via `.env`, not in source

---

## ğŸ“¦ Use Case

- You have many agents/services using OpenAI.
- You hit 429 `RateLimitError` often.
- You want to **delay and retry**, not reject.

---

## ğŸš€ Installation

```bash
git clone https://github.com/yourname/llm-queue-proxy.git
cd llm-queue-proxy
go build -o /usr/local/bin/llm_queue_proxy main.go
```

## ğŸ›  Setup (as systemd service)
1. Create config and log paths
```bash
sudo mkdir -p /etc/llm-queue-proxy /var/log/llm-queue-proxy
sudo touch /var/log/llm-queue-proxy/proxy.log
```

2. Create config file `/etc/llm-queue-proxy/proxy.env`
```bash
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxOPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1
RATE_LIMIT_PER_MIN=60
PORT=8080
```

3. Add systemd unit `/etc/systemd/system/llm-queue-proxy.service`
```ini
[Unit]
Description=LLM Queue Proxy
After=network.target

[Service]
Type=simple
EnvironmentFile=/etc/llm-queue-proxy/proxy.env
ExecStart=/usr/local/bin/llm_queue_proxy
WorkingDirectory=/var/log/llm-queue-proxy
StandardOutput=append:/var/log/llm-queue-proxy/proxy.log
StandardError=append:/var/log/llm-queue-proxy/proxy.log
Restart=on-failure
RestartSec=3

[Install]
WantedBy=multi-user.target
```

4. Enable and start
```bash
sudo systemctl daemon-reload
sudo systemctl enable llm-queue-proxy
sudo systemctl start llm-queue-proxy
```

## ğŸ“¥ How It Works
```text
[Your Agents] ---> [llm-queue-proxy] ---> [api.openai.com]
                     (rate-aware queue)
```

## ğŸ§ª Testing
```bash
curl http://localhost:8080/v1/chat/completions -H "Authorization: Bearer ..." -d ...
```

## ğŸ“ License
MIT â€” free to use and modify.
